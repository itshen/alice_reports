#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æœç´¢ç»“æœæ—¶é—´æ’åºåŠŸèƒ½
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from services.deep_research_service import DeepResearchService
from services.crawler_service import CrawlerService
from services.llm_service import LLMService

async def test_time_sorting():
    """æµ‹è¯•æœç´¢ç»“æœæŒ‰æ—¶é—´æ’åºåŠŸèƒ½"""
    print("â° æµ‹è¯•æœç´¢ç»“æœæ—¶é—´æ’åºåŠŸèƒ½")
    print("="*50)
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    crawler_service = CrawlerService()
    llm_service = LLMService()
    deep_research_service = DeepResearchService(crawler_service, llm_service)
    
    # æ¨¡æ‹Ÿæœç´¢ç»“æœæ•°æ®
    mock_search_results = [
        {
            'title': 'æ—§æ–‡ç« ï¼š2023å¹´AIå‘å±•å›é¡¾',
            'snippet': 'è¿™æ˜¯ä¸€ç¯‡å…³äº2023å¹´äººå·¥æ™ºèƒ½å‘å±•çš„å›é¡¾æ–‡ç« ',
            'url': 'https://example.com/old-article',
            'source': 'example.com',
            'date': '2023-12-01'
        },
        {
            'title': 'æœ€æ–°çªç ´ï¼š2025å¹´AIæŠ€æœ¯åˆ›æ–°',
            'snippet': 'æœ€æ–°æŠ¥é“æ˜¾ç¤ºï¼Œ2025å¹´AIæŠ€æœ¯å–å¾—é‡å¤§çªç ´',
            'url': 'https://example.com/latest-breakthrough',
            'source': 'tech.com',
            'date': '2025-09-07'
        },
        {
            'title': 'ä»Šæ—¥æ–°é—»ï¼šäººå·¥æ™ºèƒ½æœ€æ–°è¿›å±•',
            'snippet': 'ä»Šæ—¥æœ€æ–°æ¶ˆæ¯ï¼ŒAIé¢†åŸŸåˆæœ‰æ–°çš„è¿›å±•',
            'url': 'https://example.com/today-news',
            'source': 'news.com',
            'date': ''  # æ— æ—¥æœŸä½†æ ‡é¢˜åŒ…å«æ—¶é—´è¯æ±‡
        },
        {
            'title': 'æ™®é€šæ–‡ç« ï¼šAIåº”ç”¨æ¡ˆä¾‹',
            'snippet': 'è¿™æ˜¯ä¸€ç¯‡æ™®é€šçš„AIåº”ç”¨æ¡ˆä¾‹åˆ†æ',
            'url': 'https://example.com/normal-article',
            'source': 'blog.com',
            'date': ''
        },
        {
            'title': 'è¿‘æœŸç ”ç©¶ï¼šæœºå™¨å­¦ä¹ æ–°æ–¹æ³•',
            'snippet': 'è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œæœºå™¨å­¦ä¹ æœ‰äº†æ–°çš„æ–¹æ³•',
            'url': 'https://example.com/recent-research',
            'source': 'research.com',
            'date': '2024-08-15'
        }
    ]
    
    print("ğŸ“Š åŸå§‹æœç´¢ç»“æœ:")
    for i, result in enumerate(mock_search_results, 1):
        print(f"{i}. {result['title']}")
        print(f"   æ—¥æœŸ: {result['date'] or 'æ— '}")
        print(f"   URL: {result['url']}")
        print()
    
    # æµ‹è¯•AIé€‰æ‹©URLåŠŸèƒ½
    print("ğŸ¤– æµ‹è¯•AIé€‰æ‹©URLï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰...")
    
    try:
        selected_urls = await deep_research_service._ai_select_urls(
            mock_search_results, 
            "AIæŠ€æœ¯å‘å±•"
        )
        
        print(f"âœ… AIé€‰æ‹©äº† {len(selected_urls)} ä¸ªURL:")
        for i, url in enumerate(selected_urls, 1):
            # æ‰¾åˆ°å¯¹åº”çš„æ–‡ç« æ ‡é¢˜
            title = "æœªçŸ¥"
            for result in mock_search_results:
                if result['url'] == url:
                    title = result['title']
                    break
            print(f"{i}. {title}")
            print(f"   URL: {url}")
        
        # éªŒè¯æ˜¯å¦ä¼˜å…ˆé€‰æ‹©äº†æœ€æ–°çš„å†…å®¹
        expected_order = [
            'https://example.com/latest-breakthrough',  # 2025å¹´ + æœ€æ–°
            'https://example.com/today-news',           # ä»Šæ—¥
            'https://example.com/recent-research'       # è¿‘æœŸ + 2024å¹´
        ]
        
        print(f"\nğŸ“ˆ æ—¶é—´æ’åºéªŒè¯:")
        if selected_urls == expected_order:
            print("âœ… æ—¶é—´æ’åºæ­£ç¡®ï¼ä¼˜å…ˆé€‰æ‹©äº†æœ€æ–°å†…å®¹")
        else:
            print("âš ï¸ æ—¶é—´æ’åºå¯èƒ½éœ€è¦è°ƒæ•´")
            print(f"æœŸæœ›é¡ºåº: {expected_order}")
            print(f"å®é™…é¡ºåº: {selected_urls}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_sorting_algorithm():
    """æµ‹è¯•æ’åºç®—æ³•é€»è¾‘"""
    print("\nğŸ”§ æµ‹è¯•æ’åºç®—æ³•é€»è¾‘...")
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    crawler_service = CrawlerService()
    llm_service = LLMService()
    deep_research_service = DeepResearchService(crawler_service, llm_service)
    
    # æµ‹è¯•æ•°æ®
    test_results = [
        {'title': '2023å¹´æŠ¥å‘Š', 'snippet': 'æ—§æ•°æ®', 'date': '2023-01-01', 'url': 'url1'},
        {'title': 'æœ€æ–°2025å¹´æ•°æ®', 'snippet': 'æœ€æ–°ä¿¡æ¯', 'date': '2025-09-01', 'url': 'url2'},
        {'title': 'ä»Šæ—¥æ–°é—»', 'snippet': 'ä»Šæ—¥æœ€æ–°', 'date': '', 'url': 'url3'},
        {'title': 'æ™®é€šæ–‡ç« ', 'snippet': 'æ™®é€šå†…å®¹', 'date': '', 'url': 'url4'},
    ]
    
    # æ¨¡æ‹Ÿæ’åºé€»è¾‘ï¼ˆä¸å®é™…ä»£ç ä¸€è‡´ï¼‰
    sorted_results = []
    for result in test_results:
        date_score = 0
        
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()
        
        # æœ€æ–°æ—¶é—´è¯æ±‡å¾—åˆ†æœ€é«˜
        latest_keywords = ['2025', 'æœ€æ–°', 'ä»Šæ—¥', 'åˆšåˆš', 'latest', 'today']
        recent_keywords = ['2024', 'è¿‘æœŸ', 'æœ€è¿‘', 'recent', 'new']
        
        for keyword in latest_keywords:
            if keyword in title or keyword in snippet:
                date_score += 100
        
        for keyword in recent_keywords:
            if keyword in title or keyword in snippet:
                date_score += 50
        
        # å¦‚æœæœ‰å…·ä½“æ—¥æœŸï¼Œæ ¹æ®å¹´ä»½ç»™åˆ†
        if result.get('date'):
            date_str = result['date']
            if '2025' in date_str:
                date_score += 90
            elif '2024' in date_str:
                date_score += 60
            elif '2023' in date_str:
                date_score += 30
            else:
                date_score += 10
        
        sorted_results.append((result, date_score))
    
    sorted_results.sort(key=lambda x: x[1], reverse=True)
    
    print("ğŸ“Š æ’åºç»“æœ:")
    for i, (result, score) in enumerate(sorted_results, 1):
        print(f"{i}. {result['title']} (åˆ†æ•°: {score})")
    
    # éªŒè¯æ’åºæ˜¯å¦æ­£ç¡®ï¼ˆæ ¹æ®æ–°çš„è¯„åˆ†è§„åˆ™ï¼‰
    # æœ€æ–°2025å¹´æ•°æ®: 100(æœ€æ–°) + 100(2025) + 90(2025æ—¥æœŸ) = 290
    # ä»Šæ—¥æ–°é—»: 100(ä»Šæ—¥) + 100(æœ€æ–°) = 200  
    # 2023å¹´æŠ¥å‘Š: 30(2023æ—¥æœŸ) = 30
    # æ™®é€šæ–‡ç« : 0
    expected_order = ['æœ€æ–°2025å¹´æ•°æ®', 'ä»Šæ—¥æ–°é—»', '2023å¹´æŠ¥å‘Š', 'æ™®é€šæ–‡ç« ']
    actual_order = [result[0]['title'] for result in sorted_results]
    
    if actual_order == expected_order:
        print("âœ… æ’åºç®—æ³•æ­£ç¡®ï¼")
        return True
    else:
        print(f"âŒ æ’åºç®—æ³•éœ€è¦è°ƒæ•´")
        print(f"æœŸæœ›: {expected_order}")
        print(f"å®é™…: {actual_order}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æœç´¢ç»“æœæ—¶é—´æ’åºæµ‹è¯•")
    print("="*60)
    
    try:
        # æµ‹è¯•æ’åºç®—æ³•
        algo_success = await test_sorting_algorithm()
        
        # æµ‹è¯•å®Œæ•´æµç¨‹ï¼ˆéœ€è¦LLMï¼Œå¯èƒ½ä¼šå¤±è´¥ï¼‰
        print("\n" + "="*60)
        full_success = await test_time_sorting()
        
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»:")
        print(f"   æ’åºç®—æ³•: {'âœ… é€šè¿‡' if algo_success else 'âŒ å¤±è´¥'}")
        print(f"   å®Œæ•´æµç¨‹: {'âœ… é€šè¿‡' if full_success else 'âŒ å¤±è´¥'}")
        
        if algo_success:
            print("\nğŸ‰ æ—¶é—´æ’åºåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
            print("ğŸ’¡ ç°åœ¨æœç´¢ç»“æœä¼š:")
            print("   1. ä¼˜å…ˆé€‰æ‹©æœ‰æ˜ç¡®æ—¥æœŸçš„æœ€æ–°å†…å®¹")
            print("   2. è¯†åˆ«æ ‡é¢˜ä¸­çš„æ—¶é—´å…³é”®è¯")
            print("   3. æŒ‰æ—¶æ•ˆæ€§æ’åºåé€‰æ‹©å‰3ç¯‡")
            return True
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ’åºé€»è¾‘")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
