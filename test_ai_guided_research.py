#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•AIæŒ‡å¯¼çš„æ·±åº¦ç ”ç©¶æµç¨‹
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app import app
from services.deep_research_service import DeepResearchService
from services.crawler_service import CrawlerService
from services.llm_service import LLMService
from models import GlobalSettings, ReportConfig, CrawlerConfig, CrawlRecord
from datetime import datetime, timedelta

def create_mock_report_config():
    """åˆ›å»ºæ¨¡æ‹ŸæŠ¥å‘Šé…ç½®"""
    class MockReportConfig:
        def __init__(self):
            self.name = "AIæŠ€æœ¯å‘å±•è¶‹åŠ¿ç ”ç©¶"
            self.purpose = "åˆ†æAIæŠ€æœ¯åœ¨2025å¹´çš„å‘å±•è¶‹åŠ¿å’Œæœºé‡"
            self.research_focus = "é‡ç‚¹å…³æ³¨å¤§æ¨¡å‹æŠ€æœ¯ã€å¤šæ¨¡æ€AIã€AIåº”ç”¨è½åœ°"
            self.filter_keywords = "AI,äººå·¥æ™ºèƒ½,å¤§æ¨¡å‹,æœºå™¨å­¦ä¹ "
            self.time_range = "æœ€è¿‘7å¤©"
            self.data_sources = [1, 2]  # å‡è®¾çš„çˆ¬è™«ID
    
    return MockReportConfig()

def create_mock_knowledge_base():
    """åˆ›å»ºæ¨¡æ‹ŸçŸ¥è¯†åº“æ•°æ®"""
    return [
        {
            'title': 'OpenAIå‘å¸ƒGPT-5é¢„è§ˆç‰ˆï¼Œæ€§èƒ½å¤§å¹…æå‡',
            'content': 'OpenAIè¿‘æ—¥å‘å¸ƒäº†GPT-5çš„é¢„è§ˆç‰ˆæœ¬ï¼Œåœ¨æ¨ç†èƒ½åŠ›ã€å¤šæ¨¡æ€ç†è§£ç­‰æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ã€‚æ–°æ¨¡å‹åœ¨æ•°å­¦ã€ç¼–ç¨‹ã€ç§‘å­¦æ¨ç†ç­‰ä»»åŠ¡ä¸Šçš„è¡¨ç°æ¯”GPT-4æå‡äº†30%ä»¥ä¸Š...',
            'url': 'https://example.com/gpt5-preview',
            'source': 'TechCrunch',
            'date': '2025-01-15',
            'crawled_at': '2025-01-15T10:00:00'
        },
        {
            'title': 'è°·æ­ŒGemini 2.0æ­£å¼å‘å¸ƒï¼Œæ”¯æŒå®æ—¶æ¨ç†',
            'content': 'è°·æ­Œå‘å¸ƒäº†Gemini 2.0æ¨¡å‹ï¼Œæ–°å¢äº†å®æ—¶æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨å¯¹è¯è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å›ç­”ç­–ç•¥ã€‚è¯¥æ¨¡å‹åœ¨å¤šè½®å¯¹è¯å’Œå¤æ‚ä»»åŠ¡å¤„ç†æ–¹é¢è¡¨ç°å‡ºè‰²...',
            'url': 'https://example.com/gemini-2-0',
            'source': 'Google AI Blog',
            'date': '2025-01-14',
            'crawled_at': '2025-01-14T15:30:00'
        },
        {
            'title': 'ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹4.0åœ¨ä¼ä¸šåº”ç”¨ä¸­çš„å®è·µ',
            'content': 'ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹4.0åœ¨é‡‘èã€åŒ»ç–—ã€æ•™è‚²ç­‰å¤šä¸ªè¡Œä¸šå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚ç›¸æ¯”3.5ç‰ˆæœ¬ï¼Œæ–°ç‰ˆæœ¬åœ¨ä¸“ä¸šé¢†åŸŸçš„å‡†ç¡®æ€§æå‡äº†25%ï¼Œæ¨ç†é€Ÿåº¦æå‡40%...',
            'url': 'https://example.com/wenxin-4-0',
            'source': 'ç™¾åº¦AI',
            'date': '2025-01-13',
            'crawled_at': '2025-01-13T09:15:00'
        },
        {
            'title': 'AIèŠ¯ç‰‡å¸‚åœº2025å¹´é¢„æµ‹ï¼šè‹±ä¼Ÿè¾¾ä¾ç„¶é¢†å…ˆ',
            'content': 'åˆ†ææŠ¥å‘Šæ˜¾ç¤ºï¼Œ2025å¹´AIèŠ¯ç‰‡å¸‚åœºé¢„è®¡å¢é•¿45%ã€‚è‹±ä¼Ÿè¾¾H100å’Œå³å°†å‘å¸ƒçš„H200èŠ¯ç‰‡ç»§ç»­å æ®å¸‚åœºä¸»å¯¼åœ°ä½ï¼Œä½†åä¸ºã€å¯’æ­¦çºªç­‰ä¸­å›½å‚å•†å¿«é€Ÿè¿½èµ¶...',
            'url': 'https://example.com/ai-chip-market',
            'source': 'IDC Research',
            'date': '2025-01-12',
            'crawled_at': '2025-01-12T14:20:00'
        },
        {
            'title': 'Metaå‘å¸ƒLlama 3.5ï¼Œå¼€æºæ¨¡å‹æ–°çªç ´',
            'content': 'Metaå‘å¸ƒäº†å¼€æºå¤§æ¨¡å‹Llama 3.5ï¼Œåœ¨ä¿æŒå¼€æºç‰¹æ€§çš„åŒæ—¶ï¼Œæ€§èƒ½æ¥è¿‘GPT-4æ°´å¹³ã€‚è¿™ä¸€å‘å¸ƒå°†è¿›ä¸€æ­¥æ¨åŠ¨å¼€æºAIç”Ÿæ€çš„å‘å±•...',
            'url': 'https://example.com/llama-3-5',
            'source': 'Meta AI',
            'date': '2025-01-11',
            'crawled_at': '2025-01-11T11:45:00'
        }
    ]

async def test_initial_analysis():
    """æµ‹è¯•AIåˆæ­¥åˆ†æåŠŸèƒ½"""
    print("ğŸ§  æµ‹è¯•AIåˆæ­¥åˆ†æåŠŸèƒ½")
    print("="*50)
    
    try:
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        crawler_service = CrawlerService()
        llm_service = LLMService()
        deep_research_service = DeepResearchService(crawler_service, llm_service)
        
        # æ¨¡æ‹Ÿæ•°æ®
        mock_config = create_mock_report_config()
        mock_knowledge = create_mock_knowledge_base()
        
        print(f"ğŸ“š æ¨¡æ‹ŸçŸ¥è¯†åº“: {len(mock_knowledge)} ç¯‡æ–‡ç« ")
        for i, article in enumerate(mock_knowledge, 1):
            print(f"  {i}. {article['title'][:60]}...")
        
        print(f"\nğŸ¯ ç ”ç©¶é…ç½®:")
        print(f"  ä¸»é¢˜: {mock_config.purpose}")
        print(f"  ä¾§é‡ç‚¹: {mock_config.research_focus}")
        print(f"  å…³é”®è¯: {mock_config.filter_keywords}")
        
        # æ‰§è¡ŒAIåˆæ­¥åˆ†æ
        print(f"\nğŸ¤– å¼€å§‹AIåˆæ­¥åˆ†æ...")
        analysis_result = await deep_research_service._ai_initial_analysis(mock_knowledge, mock_config)
        
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"\nğŸ“Š åˆ†æç»“æœ:")
        print(f"ç°æœ‰çŸ¥è¯†æ‘˜è¦: {analysis_result.get('summary', 'æ— ')}")
        print(f"\nğŸ” çŸ¥è¯†ç©ºç™½: {analysis_result.get('gaps', 'æ— ')}")
        print(f"\nğŸ¯ ç ”ç©¶æ–¹å‘:")
        for i, direction in enumerate(analysis_result.get('directions', []), 1):
            print(f"  {i}. {direction}")
        print(f"\nğŸ”‘ ä¼˜å…ˆå…³é”®è¯: {', '.join(analysis_result.get('keywords', []))}")
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return None

async def test_research_decision():
    """æµ‹è¯•AIç ”ç©¶å†³ç­–åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ¯ æµ‹è¯•AIç ”ç©¶å†³ç­–åŠŸèƒ½")
    print("="*50)
    
    try:
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        crawler_service = CrawlerService()
        llm_service = LLMService()
        deep_research_service = DeepResearchService(crawler_service, llm_service)
        
        # æ¨¡æ‹Ÿæ•°æ®
        mock_config = create_mock_report_config()
        mock_knowledge = create_mock_knowledge_base()
        
        # æ¨¡æ‹Ÿåˆæ­¥åˆ†æç»“æœ
        mock_analysis = {
            'summary': 'ç°æœ‰æ–‡ç« ä¸»è¦è¦†ç›–äº†å¤§æ¨¡å‹æŠ€æœ¯å‘å±•ã€ä¸»è¦å‚å•†åŠ¨æ€ã€èŠ¯ç‰‡å¸‚åœºç­‰æ–¹é¢',
            'gaps': 'ç¼ºä¹å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ã€å•†ä¸šåŒ–ç¨‹åº¦åˆ†æã€ç”¨æˆ·ä½“éªŒè¯„ä¼°ç­‰æ·±åº¦å†…å®¹',
            'directions': [
                'æ·±å…¥åˆ†æGPT-5çš„æŠ€æœ¯çªç ´ç‚¹å’Œåº”ç”¨åœºæ™¯',
                'è°ƒç ”ä¼ä¸šçº§AIåº”ç”¨çš„å®é™…è½åœ°æ•ˆæœ',
                'åˆ†æAIèŠ¯ç‰‡æŠ€æœ¯å‘å±•å¯¹æ•´ä½“è¡Œä¸šçš„å½±å“'
            ],
            'keywords': ['GPT-5æŠ€æœ¯ç»†èŠ‚', 'AIä¼ä¸šåº”ç”¨æ¡ˆä¾‹', 'AIèŠ¯ç‰‡æŠ€æœ¯å‘å±•']
        }
        
        print(f"ğŸ“‹ ä½¿ç”¨æ¨¡æ‹Ÿçš„åˆæ­¥åˆ†æç»“æœ:")
        print(f"  ç°æœ‰çŸ¥è¯†: {mock_analysis['summary']}")
        print(f"  çŸ¥è¯†ç©ºç™½: {mock_analysis['gaps']}")
        print(f"  å»ºè®®å…³é”®è¯: {', '.join(mock_analysis['keywords'])}")
        
        # æµ‹è¯•å¤šè½®å†³ç­–
        for iteration in range(1, 4):
            print(f"\nğŸ”„ ç¬¬ {iteration} è½®ç ”ç©¶å†³ç­–...")
            
            decision = await deep_research_service._send_guided_research_prompt(
                mock_knowledge, mock_config, mock_analysis, iteration
            )
            
            print(f"  AIå†³ç­–: {decision.get('action', 'æœªçŸ¥')}")
            print(f"  åŸå› : {decision.get('details', 'æ— ')}")
            
            if decision.get('action') == 'search':
                keywords = decision.get('keywords', [])
                print(f"  æœç´¢å…³é”®è¯: {', '.join(keywords)}")
            elif decision.get('action') == 'finish':
                print(f"  AIå†³å®šç»“æŸç ”ç©¶")
                break
            
            # æ¨¡æ‹Ÿæ·»åŠ æ–°æ–‡ç« åˆ°çŸ¥è¯†åº“
            if decision.get('action') == 'search':
                mock_knowledge.append({
                    'title': f'ç¬¬{iteration}è½®æœç´¢è·å¾—çš„æ–°æ–‡ç« ',
                    'content': f'åŸºäºå…³é”®è¯{decision.get("keywords", [])}æœç´¢åˆ°çš„ç›¸å…³å†…å®¹...',
                    'url': f'https://example.com/search-result-{iteration}',
                    'source': f'æœç´¢æ¥æº-{iteration}',
                    'date': '2025-01-16',
                    'crawled_at': '2025-01-16T12:00:00'
                })
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_filter_and_analysis():
    """æµ‹è¯•å…³é”®è¯è¿‡æ»¤å’Œåˆ†æç»„åˆ"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•å…³é”®è¯è¿‡æ»¤å’ŒAIåˆ†æç»„åˆ")
    print("="*50)
    
    try:
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        crawler_service = CrawlerService()
        llm_service = LLMService()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        all_articles = create_mock_knowledge_base()
        
        # æ·»åŠ ä¸€äº›ä¸ç›¸å…³çš„æ–‡ç« 
        all_articles.extend([
            {
                'title': 'ä»Šæ—¥è‚¡å¸‚è¡Œæƒ…åˆ†æ',
                'content': 'ä»Šæ—¥Aè‚¡å¸‚åœºè¡¨ç°å¹³ç¨³ï¼Œæ²ªæ·±300æŒ‡æ•°å¾®è·Œ0.2%...',
                'url': 'https://example.com/stock-market',
                'source': 'è´¢ç»ç½‘',
                'date': '2025-01-15'
            },
            {
                'title': 'æ–°èƒ½æºæ±½è½¦é”€é‡åˆ›æ–°é«˜',
                'content': '2024å¹´æ–°èƒ½æºæ±½è½¦é”€é‡çªç ´800ä¸‡è¾†ï¼ŒåŒæ¯”å¢é•¿35%...',
                'url': 'https://example.com/ev-sales',
                'source': 'æ±½è½¦ä¹‹å®¶',
                'date': '2025-01-14'
            }
        ])
        
        print(f"ğŸ“š åŸå§‹æ–‡ç« æ•°: {len(all_articles)}")
        for i, article in enumerate(all_articles, 1):
            print(f"  {i}. {article['title'][:50]}...")
        
        # æµ‹è¯•å…³é”®è¯è¿‡æ»¤
        filter_keywords = "AI,äººå·¥æ™ºèƒ½,å¤§æ¨¡å‹,æœºå™¨å­¦ä¹ "
        print(f"\nğŸ” ä½¿ç”¨å…³é”®è¯è¿‡æ»¤: {filter_keywords}")
        
        filtered_articles = llm_service.filter_articles_by_keywords(all_articles, filter_keywords)
        
        print(f"âœ… è¿‡æ»¤åæ–‡ç« æ•°: {len(filtered_articles)}")
        for i, article in enumerate(filtered_articles, 1):
            print(f"  {i}. {article['title'][:50]}...")
        
        return len(filtered_articles) > 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIæŒ‡å¯¼æ·±åº¦ç ”ç©¶æµç¨‹æµ‹è¯•")
    print("="*60)
    
    try:
        # æµ‹è¯•å…³é”®è¯è¿‡æ»¤
        filter_success = await test_filter_and_analysis()
        
        # æµ‹è¯•AIåˆæ­¥åˆ†æ
        analysis_result = await test_initial_analysis()
        analysis_success = analysis_result is not None
        
        # æµ‹è¯•AIç ”ç©¶å†³ç­–
        decision_success = await test_research_decision()
        
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»:")
        print(f"   å…³é”®è¯è¿‡æ»¤: {'âœ… é€šè¿‡' if filter_success else 'âŒ å¤±è´¥'}")
        print(f"   AIåˆæ­¥åˆ†æ: {'âœ… é€šè¿‡' if analysis_success else 'âŒ å¤±è´¥'}")
        print(f"   AIç ”ç©¶å†³ç­–: {'âœ… é€šè¿‡' if decision_success else 'âŒ å¤±è´¥'}")
        
        if all([filter_success, analysis_success, decision_success]):
            print("\nğŸ‰ AIæŒ‡å¯¼ç ”ç©¶æµç¨‹æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
            print("ğŸ’¡ æ–°æµç¨‹ç‰¹ç‚¹:")
            print("   1. ğŸ“Š ä»æ•°æ®åº“è·å–æœ€è¿‘çˆ¬åˆ°çš„å†…å®¹")
            print("   2. ğŸ” æ ¹æ®ç”¨æˆ·å…³é”®è¯è¿›è¡Œæ™ºèƒ½è¿‡æ»¤")
            print("   3. ğŸ§  AIæ·±åº¦åˆ†æç°æœ‰çŸ¥è¯†ï¼Œè¯†åˆ«ç©ºç™½")
            print("   4. ğŸ¯ AIåˆ¶å®šæœ‰é’ˆå¯¹æ€§çš„ç ”ç©¶è®¡åˆ’")
            print("   5. ğŸ”„ åŸºäºåˆ†æç»“æœè¿›è¡Œè¿­ä»£æœç´¢")
            print("   6. ğŸ“ ç”ŸæˆåŸºäºå……åˆ†ç ”ç©¶çš„é«˜è´¨é‡æŠ¥å‘Š")
            return True
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    with app.app_context():
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
