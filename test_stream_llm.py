#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•LLMæµå¼è¿”å›åŠŸèƒ½
"""

import asyncio
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app import app
from services.llm_service import LLMService
from models import GlobalSettings

def test_stream_vs_normal():
    """æµ‹è¯•æµå¼è¿”å› vs æ™®é€šè¿”å›"""
    print("ğŸš€ LLMæµå¼è¿”å›åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    try:
        with app.app_context():
            # è·å–LLMè®¾ç½®
            settings = GlobalSettings.query.first()
            if not settings or not settings.llm_api_key:
                print("âŒ LLMé…ç½®æœªæ‰¾åˆ°")
                return False
            
            llm_service = LLMService()
            llm_service.update_settings(settings)
            
            # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
            test_messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæŠ€æœ¯åˆ†æå¸ˆã€‚è¯·ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯åˆ†ææŠ¥å‘Šã€‚"
                },
                {
                    "role": "user", 
                    "content": """è¯·åˆ†æäººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨2025å¹´çš„å‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬ï¼š
1. å¤§æ¨¡å‹æŠ€æœ¯çš„æœ€æ–°è¿›å±•
2. AIåœ¨å„è¡Œä¸šçš„åº”ç”¨ç°çŠ¶
3. æŠ€æœ¯æŒ‘æˆ˜å’Œå‘å±•æœºé‡
4. æœªæ¥å‘å±•é¢„æµ‹

è¯·ç”Ÿæˆä¸€ä¸ªçº¦1000å­—çš„è¯¦ç»†åˆ†ææŠ¥å‘Šã€‚"""
                }
            ]
            
            print(f"ğŸ”§ LLMé…ç½®: {settings.llm_provider} ({settings.llm_model_name})")
            print(f"ğŸ¯ æµ‹è¯•ä»»åŠ¡: ç”Ÿæˆçº¦1000å­—çš„AIæŠ€æœ¯åˆ†ææŠ¥å‘Š")
            
            # æµ‹è¯•æ™®é€šè¿”å›
            print(f"\nğŸ“ æµ‹è¯•1: æ™®é€šè¿”å›æ¨¡å¼")
            start_time = time.time()
            try:
                normal_result = llm_service._make_request(test_messages, temperature=0.7, stream=False)
                normal_time = time.time() - start_time
                
                print(f"âœ… æ™®é€šè¿”å›å®Œæˆ")
                print(f"   è€—æ—¶: {normal_time:.2f}ç§’")
                print(f"   å†…å®¹é•¿åº¦: {len(normal_result)}å­—ç¬¦")
                print(f"   é¢„è§ˆ: {normal_result[:150]}...")
                
            except Exception as e:
                print(f"âŒ æ™®é€šè¿”å›å¤±è´¥: {e}")
                normal_result = None
                normal_time = 0
            
            # æµ‹è¯•æµå¼è¿”å›
            print(f"\nğŸ“¡ æµ‹è¯•2: æµå¼è¿”å›æ¨¡å¼")
            start_time = time.time()
            try:
                print("æµå¼è¾“å‡ºå¼€å§‹:")
                print("-" * 50)
                stream_result = llm_service._make_request(test_messages, temperature=0.7, stream=True)
                stream_time = time.time() - start_time
                
                print("\n" + "-" * 50)
                print(f"âœ… æµå¼è¿”å›å®Œæˆ")
                print(f"   è€—æ—¶: {stream_time:.2f}ç§’") 
                print(f"   å†…å®¹é•¿åº¦: {len(stream_result)}å­—ç¬¦")
                
            except Exception as e:
                print(f"âŒ æµå¼è¿”å›å¤±è´¥: {e}")
                stream_result = None
                stream_time = 0
            
            # å¯¹æ¯”ç»“æœ
            print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
            if normal_result and stream_result:
                print(f"   æ™®é€šæ¨¡å¼: {normal_time:.2f}ç§’ ({len(normal_result)}å­—ç¬¦)")
                print(f"   æµå¼æ¨¡å¼: {stream_time:.2f}ç§’ ({len(stream_result)}å­—ç¬¦)")
                
                if stream_time > 0 and normal_time > 0:
                    improvement = ((normal_time - stream_time) / normal_time) * 100
                    print(f"   æµå¼æ¨¡å¼ç”¨æˆ·ä½“éªŒæå‡: {improvement:.1f}%")
                
                # æ£€æŸ¥å†…å®¹è´¨é‡
                if abs(len(normal_result) - len(stream_result)) / max(len(normal_result), len(stream_result)) < 0.1:
                    print(f"   å†…å®¹è´¨é‡: âœ… ä¸¤ç§æ¨¡å¼å†…å®¹é•¿åº¦æ¥è¿‘")
                else:
                    print(f"   å†…å®¹è´¨é‡: âš ï¸ ä¸¤ç§æ¨¡å¼å†…å®¹é•¿åº¦å·®å¼‚è¾ƒå¤§")
            
            return normal_result is not None and stream_result is not None
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def test_timeout_resistance():
    """æµ‹è¯•æµå¼è¿”å›çš„è¶…æ—¶æŠ—æ€§"""
    print(f"\nğŸ• æµå¼è¿”å›è¶…æ—¶æŠ—æ€§æµ‹è¯•")
    print("="*50)
    
    try:
        with app.app_context():
            settings = GlobalSettings.query.first()
            if not settings or not settings.llm_api_key:
                print("âŒ LLMé…ç½®æœªæ‰¾åˆ°")
                return False
            
            llm_service = LLMService()
            llm_service.update_settings(settings)
            
            # å‡†å¤‡æ›´å¤æ‚çš„ä»»åŠ¡ï¼ˆå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
            complex_messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ·±åº¦ç ”ç©¶åˆ†æå¸ˆã€‚è¯·ç”Ÿæˆè¯¦ç»†ã€æ·±å…¥çš„ç ”ç©¶æŠ¥å‘Šã€‚"
                },
                {
                    "role": "user",
                    "content": """è¯·ç”Ÿæˆä¸€ä»½å…³äº"AIæŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸äº§ä¸šåŒ–åº”ç”¨"çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

1. æŠ€æœ¯å‘å±•å†ç¨‹å›é¡¾
2. å½“å‰æŠ€æœ¯çƒ­ç‚¹åˆ†æ 
3. ä¸»è¦å‚å•†ç«äº‰æ ¼å±€
4. è¡Œä¸šåº”ç”¨æ¡ˆä¾‹ç ”ç©¶
5. æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ
6. å¸‚åœºè§„æ¨¡ä¸æŠ•èµ„è¶‹åŠ¿
7. æ”¿ç­–æ³•è§„å½±å“åˆ†æ
8. æœªæ¥5å¹´å‘å±•é¢„æµ‹
9. é£é™©è¯„ä¼°ä¸æœºé‡åˆ†æ
10. æˆ˜ç•¥å»ºè®®ä¸è¡ŒåŠ¨è®¡åˆ’

è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹è¯¦å®ã€é€»è¾‘æ¸…æ™°ã€æ•°æ®æ”¯æ’‘å……åˆ†ï¼Œç›®æ ‡é•¿åº¦2000-3000å­—ã€‚"""
                }
            ]
            
            print(f"ğŸ¯ å¤æ‚ä»»åŠ¡: ç”Ÿæˆ2000-3000å­—æ·±åº¦ç ”ç©¶æŠ¥å‘Š")
            
            start_time = time.time()
            try:
                print("å¼€å§‹æµå¼ç”Ÿæˆå¤æ‚æŠ¥å‘Š...")
                print("-" * 50)
                
                result = llm_service._make_request(complex_messages, temperature=0.7, stream=True)
                end_time = time.time()
                
                print("\n" + "-" * 50)
                print(f"âœ… å¤æ‚ä»»åŠ¡æµå¼è¿”å›æˆåŠŸ")
                print(f"   è€—æ—¶: {end_time - start_time:.2f}ç§’")
                print(f"   å†…å®¹é•¿åº¦: {len(result)}å­—ç¬¦")
                print(f"   æ˜¯å¦è¾¾åˆ°ç›®æ ‡é•¿åº¦: {'âœ… æ˜¯' if len(result) >= 2000 else 'âŒ å¦'}")
                
                return True
                
            except Exception as e:
                print(f"âŒ å¤æ‚ä»»åŠ¡å¤±è´¥: {e}")
                return False
                
    except Exception as e:
        print(f"âŒ è¶…æ—¶æŠ—æ€§æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ å¯åŠ¨LLMæµå¼è¿”å›æµ‹è¯•...")
    
    results = {}
    
    # æµ‹è¯•åŸºæœ¬æµå¼åŠŸèƒ½
    basic_success = test_stream_vs_normal()
    results["åŸºæœ¬æµå¼åŠŸèƒ½"] = basic_success
    
    # æµ‹è¯•è¶…æ—¶æŠ—æ€§
    timeout_success = test_timeout_resistance()
    results["è¶…æ—¶æŠ—æ€§"] = timeout_success
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ LLMæµå¼è¿”å›æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    total_tests = len(results)
    passed_tests = sum(1 for result in results.values() if result)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLMæµå¼è¿”å›åŠŸèƒ½æ­£å¸¸")
        print("ğŸ’¡ ä¼˜åŠ¿:")
        print("   âœ… è§£å†³è¶…æ—¶é—®é¢˜ - æµå¼è¿”å›å¯ä»¥å¤„ç†é•¿æ—¶é—´ç”Ÿæˆä»»åŠ¡")
        print("   âœ… æå‡ç”¨æˆ·ä½“éªŒ - å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿›åº¦")
        print("   âœ… æ›´å¥½çš„ç¨³å®šæ€§ - å‡å°‘ç½‘ç»œè¶…æ—¶é£é™©")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æµå¼è¿”å›å®ç°")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
