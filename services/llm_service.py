#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
æ”¯æŒé€šä¹‰åƒé—®ã€OpenRouterç­‰å¤šç§LLMæœåŠ¡å•†
"""

import requests
import json
import logging
from typing import List, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)

class LLMService:
    """å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ç±»"""
    
    def __init__(self):
        self.settings = None
    
    def update_settings(self, settings):
        """æ›´æ–°LLMè®¾ç½®"""
        self.settings = settings
    
    def test_connection(self, settings=None) -> Dict[str, Any]:
        """æµ‹è¯•LLMè¿æ¥"""
        test_settings = settings or self.settings
        
        if not test_settings or not test_settings.llm_api_key:
            return {
                'success': False,
                'message': 'API Keyæœªé…ç½®'
            }
        
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {test_settings.llm_api_key}'
        }
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¶ˆæ¯
        data = {
            'model': test_settings.llm_model_name or 'qwen-plus',
            'messages': [
                {
                    'role': 'user',
                    'content': 'è¯·å›å¤"è¿æ¥æµ‹è¯•æˆåŠŸ"'
                }
            ],
            'temperature': 0.1,
            'max_tokens': 50
        }
        
        try:
            response = requests.post(
                f"{test_settings.llm_base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    return {
                        'success': True,
                        'message': f'è¿æ¥æˆåŠŸï¼æ¨¡å‹å“åº”: {content}',
                        'model': test_settings.llm_model_name,
                        'provider': test_settings.llm_provider
                    }
                else:
                    return {
                        'success': False,
                        'message': 'å“åº”æ ¼å¼å¼‚å¸¸'
                    }
            else:
                error_msg = f"HTTP {response.status_code}"
                try:
                    error_detail = response.json()
                    if 'error' in error_detail:
                        error_msg = error_detail['error'].get('message', error_msg)
                except:
                    pass
                
                return {
                    'success': False,
                    'message': f'è¿æ¥å¤±è´¥: {error_msg}'
                }
                
        except requests.exceptions.Timeout:
            return {
                'success': False,
                'message': 'è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIåœ°å€'
            }
        except requests.exceptions.ConnectionError:
            return {
                'success': False,
                'message': 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥APIåœ°å€'
            }
        except Exception as e:
            logger.error(f"LLMè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
            }
    
    def _make_request(self, messages: List[Dict], temperature: float = 0.7, stream: bool = False) -> str:
        """å‘é€è¯·æ±‚åˆ°LLMæœåŠ¡"""
        if not self.settings or not self.settings.llm_api_key:
            raise Exception("LLMè®¾ç½®æœªé…ç½®")
        
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.settings.llm_api_key}'
        }
        
        data = {
            'model': self.settings.llm_model_name,
            'messages': messages,
            'temperature': temperature,
            'max_tokens': 4000,
            'stream': stream
        }
        
        try:
            if stream:
                return self._handle_stream_request(headers, data)
            else:
                response = requests.post(
                    f"{self.settings.llm_base_url}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                else:
                    logger.error(f"LLMè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                    raise Exception(f"LLMè¯·æ±‚å¤±è´¥: {response.status_code}")
        
        except requests.exceptions.RequestException as e:
            logger.error(f"LLMè¯·æ±‚å¼‚å¸¸: {e}")
            raise Exception(f"LLMè¯·æ±‚å¼‚å¸¸: {e}")
    
    def _handle_stream_request(self, headers: Dict, data: Dict) -> str:
        """å¤„ç†æµå¼è¯·æ±‚"""
        import json
        
        try:
            response = requests.post(
                f"{self.settings.llm_base_url}/chat/completions",
                headers=headers,
                json=data,
                stream=True,
                timeout=300  # æµå¼è¯·æ±‚æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            )
            
            if response.status_code != 200:
                logger.error(f"æµå¼LLMè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                raise Exception(f"æµå¼LLMè¯·æ±‚å¤±è´¥: {response.status_code}")
            
            content = ""
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith('data: '):
                        line_str = line_str[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                        
                        if line_str.strip() == '[DONE]':
                            break
                            
                        try:
                            chunk_data = json.loads(line_str)
                            if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                                delta = chunk_data['choices'][0].get('delta', {})
                                if 'content' in delta:
                                    content += delta['content']
                                    # å®æ—¶æ˜¾ç¤ºè¿›åº¦ï¼ˆå¯é€‰ï¼‰
                                    print(delta['content'], end='', flush=True)
                        except json.JSONDecodeError:
                            # å¿½ç•¥æ— æ³•è§£æçš„è¡Œ
                            continue
            
            logger.info(f"æµå¼è¯·æ±‚å®Œæˆï¼Œç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)}")
            return content
            
        except requests.exceptions.RequestException as e:
            logger.error(f"æµå¼LLMè¯·æ±‚å¼‚å¸¸: {e}")
            raise Exception(f"æµå¼LLMè¯·æ±‚å¼‚å¸¸: {e}")
    
    def generate_url_regex(self, settings, page_content: str, url: str, requirement: str = 'åŒ¹é…æ–‡ç« è¯¦æƒ…é¡µé“¾æ¥') -> Dict[str, Any]:
        """ä½¿ç”¨AIç”ŸæˆURLæ­£åˆ™è¡¨è¾¾å¼"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä¸“å®¶ã€‚åˆ†æç½‘é¡µå†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªèƒ½å¤ŸåŒ¹é…æ–‡ç« è¯¦æƒ…é¡µé“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚

ä¸¥æ ¼è¦æ±‚ï¼š
1. åªè¿”å›ä¸€è¡Œæ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–è¯´æ˜
2. å¿…é¡»ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼š(æ­£åˆ™è¡¨è¾¾å¼)"
3. ç¤ºä¾‹æ ¼å¼ï¼š(https://www\.news\.cn/comments/\d{8}/[a-f0-9]{32}/c\.html)"
4. ç¡®ä¿æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•æ­£ç¡®ï¼Œç‰¹åˆ«æ³¨æ„æ–¹æ‹¬å·[]å¿…é¡»æ­£ç¡®é—­åˆ
5. ä½¿ç”¨è½¬ä¹‰å­—ç¬¦\æ¥è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦å¦‚ç‚¹å·\.
6. ä¸è¦ä½¿ç”¨æœªé—­åˆçš„å­—ç¬¦é›†[æˆ–å…¶ä»–è¯­æ³•é”™è¯¯"""
                },
                {
                    "role": "user",
                    "content": f"""
ç½‘ç«™URLï¼š{url}

ç”¨æˆ·éœ€æ±‚ï¼š{requirement}

ç½‘é¡µHTMLå†…å®¹ï¼ˆå‰3000å­—ç¬¦ï¼‰ï¼š
{page_content[:3000]}

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚åˆ†æè¿™ä¸ªç½‘é¡µçš„ç»“æ„ï¼Œç”Ÿæˆä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…ç¬¦åˆè¦æ±‚çš„é“¾æ¥ã€‚
æ³¨æ„è§‚å¯Ÿé“¾æ¥çš„ç‰¹å¾ï¼Œæ¯”å¦‚åŒ…å«ç‰¹å®šè·¯å¾„ã€æ–‡ä»¶æ‰©å±•åæˆ–IDæ¨¡å¼ã€‚

ç”¨æˆ·çš„å…·ä½“éœ€æ±‚æ˜¯ï¼š{requirement}
è¯·ç¡®ä¿ç”Ÿæˆçš„æ­£åˆ™è¡¨è¾¾å¼èƒ½å‡†ç¡®åŒ¹é…åˆ°ç”¨æˆ·æƒ³è¦çš„é“¾æ¥ç±»å‹ã€‚
"""
                }
            ]
            
            # ä½¿ç”¨ä¸´æ—¶è®¾ç½®
            temp_settings = self.settings
            self.settings = settings
            
            result = self._make_request(messages, temperature=0.3)
            
            # æ¢å¤åŸè®¾ç½®
            self.settings = temp_settings
            
            # æå–æ­£åˆ™è¡¨è¾¾å¼
            import re
            
            # æ¸…ç†AIè¿”å›çš„ç»“æœ
            cleaned_result = result.strip()
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            cleaned_result = re.sub(r'^```.*?\n', '', cleaned_result, flags=re.MULTILINE)
            cleaned_result = re.sub(r'\n```$', '', cleaned_result)
            cleaned_result = re.sub(r'^`|`$', '', cleaned_result).strip()
            
            # å°è¯•å¤šç§æ¨¡å¼æå–æ­£åˆ™è¡¨è¾¾å¼
            extracted_regex = None
            
            # æ¨¡å¼1: href="(...)" æ ¼å¼
            pattern1 = re.search(r'href="([^"]+)"', cleaned_result)
            if pattern1:
                extracted_regex = pattern1.group(0)
            
            # æ¨¡å¼2: ç›´æ¥çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç¬¬ä¸€è¡Œï¼‰
            if not extracted_regex:
                lines = cleaned_result.split('\n')
                if lines:
                    extracted_regex = lines[0].strip()
            
            # æ¨¡å¼3: å¦‚æœåŒ…å«æ‹¬å·ï¼Œå°è¯•æå–æ‹¬å·å†…å®¹
            if not extracted_regex:
                pattern3 = re.search(r'\(([^)]+)\)', cleaned_result)
                if pattern3:
                    extracted_regex = f'href="({pattern3.group(1)})"'
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨æ¸…ç†åçš„ç»“æœ
            if not extracted_regex:
                extracted_regex = cleaned_result
            
            # éªŒè¯æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•
            try:
                re.compile(extracted_regex)
                logger.info(f"AIç”Ÿæˆçš„æ­£åˆ™è¡¨è¾¾å¼: {extracted_regex}")
            except re.error as e:
                logger.error(f"AIç”Ÿæˆçš„æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•é”™è¯¯: {e}, åŸå§‹ç»“æœ: {result}")
                # å¦‚æœè¯­æ³•é”™è¯¯ï¼Œè¿”å›ä¸€ä¸ªå®‰å…¨çš„é»˜è®¤æ­£åˆ™è¡¨è¾¾å¼
                extracted_regex = r'href="([^"]*\.html[^"]*)"'
                logger.info(f"ä½¿ç”¨é»˜è®¤æ­£åˆ™è¡¨è¾¾å¼: {extracted_regex}")
            
            return {
                'success': True,
                'regex': extracted_regex,
                'explanation': 'åŸºäºé¡µé¢ç»“æ„åˆ†æç”Ÿæˆçš„æ­£åˆ™è¡¨è¾¾å¼'
            }
        
        except Exception as e:
            logger.error(f"AIç”Ÿæˆæ­£åˆ™è¡¨è¾¾å¼å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ­£åˆ™è¡¨è¾¾å¼
            return {
                'success': True,
                'regex': r'href="([^"]*\.html[^"]*)"',
                'explanation': 'ä½¿ç”¨é»˜è®¤æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåŒ¹é….htmlé“¾æ¥ï¼‰'
            }
    
    def generate_regex_from_samples(self, page_content: str, sample_titles: List[str]) -> str:
        """æ ¹æ®æ ·æœ¬æ ‡é¢˜ç”Ÿæˆæ­£åˆ™è¡¨è¾¾å¼"""
        if not sample_titles:
            return r'href="([^"]*\.html?[^"]*)"'
        
        try:
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æä¾›çš„ç½‘é¡µå†…å®¹å’Œæ ·æœ¬æ ‡é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªèƒ½å¤ŸåŒ¹é…ç›¸å…³æ–‡ç« é“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚åªè¿”å›æ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"
                },
                {
                    "role": "user",
                    "content": f"""
ç½‘é¡µå†…å®¹ç‰‡æ®µï¼š
{page_content[:2000]}

ç”¨æˆ·æƒ³è¦åŒ¹é…çš„æ–‡ç« æ ‡é¢˜æ ·æœ¬ï¼š
{chr(10).join(sample_titles)}

è¯·ç”Ÿæˆä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…è¿™äº›æ–‡ç« çš„é“¾æ¥URLã€‚æ­£åˆ™è¡¨è¾¾å¼åº”è¯¥èƒ½å¤Ÿä»hrefå±æ€§ä¸­æå–å®Œæ•´çš„URLã€‚
"""
                }
            ]
            
            result = self._make_request(messages, temperature=0.3)
            
            # æå–æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå»é™¤å¯èƒ½çš„è§£é‡Šæ–‡å­—ï¼‰
            import re
            regex_pattern = re.search(r'r?["\']([^"\']+)["\']', result)
            if regex_pattern:
                return regex_pattern.group(1)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¼•å·åŒ…å›´çš„æ­£åˆ™ï¼Œç›´æ¥è¿”å›ç»“æœ
                return result.strip()
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ­£åˆ™è¡¨è¾¾å¼å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ­£åˆ™è¡¨è¾¾å¼
            return r'href="([^"]*\.html?[^"]*)"'
    
    def filter_articles_by_keywords(self, articles: List[Dict], keywords: str) -> List[Dict]:
        """æ ¹æ®å…³é”®è¯è¿‡æ»¤æ–‡ç« """
        if not keywords.strip():
            return articles
        
        keyword_list = [k.strip() for k in keywords.split(',') if k.strip()]
        if not keyword_list:
            return articles
        
        filtered_articles = []
        for article in articles:
            # å®‰å…¨åœ°è·å–æ ‡é¢˜å’Œå†…å®¹ï¼Œç¡®ä¿ä¸æ˜¯None
            title = article.get('title') or ''
            content = article.get('content') or ''
            
            # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
            title_lower = title.lower() if title else ''
            content_lower = content.lower() if content else ''
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€å…³é”®è¯
            for keyword in keyword_list:
                keyword_lower = keyword.lower()
                if keyword_lower in title_lower or keyword_lower in content_lower:
                    filtered_articles.append(article)
                    break
        
        return filtered_articles
    
    def generate_simple_report(self, articles: List[Dict], report_config) -> str:
        """ç”Ÿæˆç®€å•æŠ¥å‘Šï¼ˆæ–°é—»æ‘˜è¦ï¼‰"""
        if not articles:
            return "æœ¬æœŸæœªå‘ç°ç›¸å…³æ–°é—»ã€‚"
        
        try:
            # æ„å»ºæ–‡ç« æ‘˜è¦
            article_summaries = []
            for i, article in enumerate(articles[:10], 1):  # æœ€å¤š10ç¯‡æ–‡ç« 
                summary = f"{i}. **{article.get('title', 'æ— æ ‡é¢˜')}**\n"
                if article.get('author'):
                    summary += f"   ä½œè€…ï¼š{article['author']}\n"
                if article.get('date'):
                    summary += f"   æ—¶é—´ï¼š{article['date']}\n"
                if article.get('url'):
                    summary += f"   é“¾æ¥ï¼š{article['url']}\n"
                
                # æ·»åŠ å†…å®¹æ‘˜è¦
                content = article.get('content', '')
                if content:
                    content_preview = content[:200] + "..." if len(content) > 200 else content
                    summary += f"   æ‘˜è¦ï¼š{content_preview}\n"
                
                article_summaries.append(summary)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = f"""# {report_config.name}

**ç”Ÿæˆæ—¶é—´ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ•°æ®æºï¼š** {report_config.data_sources}
**å…³é”®è¯ï¼š** {report_config.filter_keywords}
**æ—¶é—´èŒƒå›´ï¼š** {report_config.time_range}

## ğŸ“° æ–°é—»æ‘˜è¦

æœ¬æœŸå…±æ”¶é›†åˆ° {len(articles)} æ¡ç›¸å…³æ–°é—»ï¼š

{chr(10).join(article_summaries)}

---
*æœ¬æŠ¥å‘Šç”±æ™ºèƒ½ä¿¡æ¯åˆ†æå¹³å°è‡ªåŠ¨ç”Ÿæˆ*
"""
            
            return report
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆç®€å•æŠ¥å‘Šå¤±è´¥: {e}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{e}"
    
    def generate_deep_research_report(self, articles: List[Dict], report_config) -> str:
        """ç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Š"""
        if not articles:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‚"
        
        try:
            # å‡†å¤‡æ–‡ç« å†…å®¹
            articles_content = []
            for article in articles[:20]:  # æœ€å¤šåˆ†æ20ç¯‡æ–‡ç« 
                content = f"æ ‡é¢˜ï¼š{article.get('title', '')}\n"
                content += f"å†…å®¹ï¼š{article.get('content', '')[:1000]}\n"  # é™åˆ¶é•¿åº¦
                content += f"æ¥æºï¼š{article.get('url', '')}\n"
                articles_content.append(content)
            
            messages = [
                {
                    "role": "system",
                    "content": f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¿¡æ¯åˆ†æå¸ˆå’Œç ”ç©¶å‘˜ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡ç« å†…å®¹ï¼Œå›´ç»•ä»¥ä¸‹ç ”ç©¶é‡ç‚¹è¿›è¡Œæ·±å…¥åˆ†æï¼š

{report_config.research_focus}

è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. æ‰§è¡Œæ‘˜è¦
2. å…³é”®å‘ç°
3. æ·±åº¦åˆ†æ
4. è¶‹åŠ¿æ´å¯Ÿ
5. ç»“è®ºä¸å»ºè®®

æŠ¥å‘Šåº”è¯¥ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ·±åº¦ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚"""
                },
                {
                    "role": "user",
                    "content": f"""
ç ”ç©¶ç›®çš„ï¼š{report_config.purpose}

ç›¸å…³æ–‡ç« å†…å®¹ï¼š
{chr(10).join(articles_content)}

è¯·åŸºäºä»¥ä¸Šå†…å®¹ç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‚
"""
                }
            ]
            
            result = self._make_request(messages, temperature=0.7)
            
            # æ·»åŠ æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯
            header = f"""# {report_config.name} - æ·±åº¦ç ”ç©¶æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç ”ç©¶ç›®çš„ï¼š** {report_config.purpose}
**ç ”ç©¶é‡ç‚¹ï¼š** {report_config.research_focus}
**åˆ†ææ–‡ç« æ•°ï¼š** {len(articles)}

---

"""
            
            footer = f"""

---

## ğŸ“Š æ•°æ®æ¥æº

æœ¬æŠ¥å‘ŠåŸºäºä»¥ä¸‹ {len(articles)} ç¯‡æ–‡ç« è¿›è¡Œåˆ†æï¼š

"""
            
            # æ·»åŠ æ•°æ®æ¥æºåˆ—è¡¨
            for i, article in enumerate(articles[:10], 1):
                footer += f"{i}. [{article.get('title', 'æ— æ ‡é¢˜')}]({article.get('url', '#')})\n"
            
            footer += "\n*æœ¬æŠ¥å‘Šç”±æ™ºèƒ½ä¿¡æ¯åˆ†æå¹³å°è‡ªåŠ¨ç”Ÿæˆ*"
            
            return header + result + footer
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Šå¤±è´¥: {e}")
            return f"æ·±åº¦ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{e}"
    
    def search_web_for_topic(self, topic: str, serp_api_key: str) -> List[Dict]:
        """ä½¿ç”¨æœç´¢APIè·å–ä¸»é¢˜ç›¸å…³ä¿¡æ¯"""
        if not serp_api_key:
            logger.warning("SERP APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡ç½‘ç»œæœç´¢")
            return []
        
        try:
            import requests
            
            logger.info(f"å¼€å§‹æœç´¢ä¸»é¢˜: {topic}")
            
            # ä½¿ç”¨SerpAPIè¿›è¡Œæœç´¢ï¼ŒåŒ¹é…å®é™…APIæ ¼å¼
            search_url = "https://serpapi.com/search"
            params = {
                'engine': 'google',
                'q': topic,
                'api_key': serp_api_key,
                'num': 10,  # è·å–å‰10ä¸ªç»“æœ
                'hl': 'zh-cn',  # ä¸­æ–‡æœç´¢
                'gl': 'cn',  # ä¸­å›½åœ°åŒº
                'json_restrictor': 'organic_results[].{position,title,snippet,redirect_link,date}'
            }
            
            response = requests.get(search_url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                search_results = []
                organic_results = data.get('organic_results', [])
                
                for result in organic_results:
                    # å¤„ç†redirect_linkï¼Œæå–çœŸå®URL
                    url = result.get('redirect_link', '')
                    if url and 'url=' in url:
                        # ä»Googleé‡å®šå‘é“¾æ¥ä¸­æå–çœŸå®URL
                        import urllib.parse
                        try:
                            parsed = urllib.parse.parse_qs(urllib.parse.urlparse(url).query)
                            if 'url' in parsed:
                                url = parsed['url'][0]
                        except:
                            pass  # å¦‚æœè§£æå¤±è´¥ï¼Œä¿æŒåŸURL
                    
                    # ä»URLæ¨æ–­æ¥æºåŸŸå
                    source = ''
                    if url:
                        try:
                            from urllib.parse import urlparse
                            parsed_url = urlparse(url)
                            source = parsed_url.netloc
                        except:
                            source = url[:50] + '...' if len(url) > 50 else url
                    
                    search_results.append({
                        'title': result.get('title', ''),
                        'url': url,
                        'snippet': result.get('snippet', ''),
                        'source': source,
                        'date': result.get('date', ''),
                        'position': result.get('position', 0)
                    })
                
                logger.info(f"æœç´¢å®Œæˆï¼Œè·å¾— {len(search_results)} ä¸ªç»“æœ")
                return search_results
            else:
                logger.error(f"æœç´¢APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return []
        
        except Exception as e:
            logger.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {e}")
            return []
    
    def generate_search_based_report(self, search_results: List[Dict], research_topic: str, research_focus: str) -> str:
        """åŸºäºæœç´¢ç»“æœç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Š"""
        if not search_results:
            return "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœï¼Œæ— æ³•ç”Ÿæˆç ”ç©¶æŠ¥å‘Šã€‚"
        
        try:
            # å‡†å¤‡æœç´¢ç»“æœå†…å®¹
            search_content = []
            for i, result in enumerate(search_results[:10], 1):
                content = f"æœç´¢ç»“æœ {i}:\n"
                content += f"æ ‡é¢˜ï¼š{result.get('title', '')}\n"
                content += f"æ¥æºï¼š{result.get('source', '')}\n"
                content += f"æ‘˜è¦ï¼š{result.get('snippet', '')}\n"
                content += f"é“¾æ¥ï¼š{result.get('url', '')}\n"
                if result.get('date'):
                    content += f"æ—¥æœŸï¼š{result['date']}\n"
                search_content.append(content)
            
            messages = [
                {
                    "role": "system",
                    "content": f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶åˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„æœç´¢ç»“æœï¼Œå›´ç»•ç ”ç©¶ä¸»é¢˜è¿›è¡Œæ·±å…¥åˆ†æã€‚

ç ”ç©¶ä¸»é¢˜ï¼š{research_topic}
ç ”ç©¶é‡ç‚¹ï¼š{research_focus}

è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. æ‰§è¡Œæ‘˜è¦
2. å…³é”®å‘ç°
3. æ·±åº¦åˆ†æ
4. è¶‹åŠ¿æ´å¯Ÿ
5. ç»“è®ºä¸å»ºè®®

æŠ¥å‘Šåº”è¯¥ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ·±åº¦ï¼Œå¹¶åŸºäºæœç´¢ç»“æœæä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚"""
                },
                {
                    "role": "user",
                    "content": f"""
ç ”ç©¶ä¸»é¢˜ï¼š{research_topic}
ç ”ç©¶é‡ç‚¹ï¼š{research_focus}

åŸºäºä»¥ä¸‹æœç´¢ç»“æœè¿›è¡Œæ·±åº¦åˆ†æï¼š

{chr(10).join(search_content)}

è¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‚
"""
                }
            ]
            
            result = self._make_request(messages, temperature=0.7)
            
            # æ·»åŠ æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯
            header = f"""# {research_topic} - æ·±åº¦ç ”ç©¶æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç ”ç©¶ä¸»é¢˜ï¼š** {research_topic}
**ç ”ç©¶é‡ç‚¹ï¼š** {research_focus}
**æœç´¢ç»“æœæ•°ï¼š** {len(search_results)}

---

"""
            
            footer = f"""

---

## ğŸ“Š æ•°æ®æ¥æº

æœ¬æŠ¥å‘ŠåŸºäºä»¥ä¸‹ {len(search_results)} ä¸ªæœç´¢ç»“æœè¿›è¡Œåˆ†æï¼š

"""
            
            # æ·»åŠ æœç´¢ç»“æœæ¥æºåˆ—è¡¨
            for i, result in enumerate(search_results[:10], 1):
                footer += f"{i}. [{result.get('title', 'æ— æ ‡é¢˜')}]({result.get('url', '#')}) - {result.get('source', 'æœªçŸ¥æ¥æº')}\n"
            
            footer += "\n*æœ¬æŠ¥å‘ŠåŸºäºç½‘ç»œæœç´¢ç»“æœç”±æ™ºèƒ½ä¿¡æ¯åˆ†æå¹³å°è‡ªåŠ¨ç”Ÿæˆ*"
            
            return header + result + footer
        
        except Exception as e:
            logger.error(f"ç”ŸæˆåŸºäºæœç´¢çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šå¤±è´¥: {e}")
            return f"æ·±åº¦ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{e}"

# datetimeå·²åœ¨ä¸Šé¢å¯¼å…¥
